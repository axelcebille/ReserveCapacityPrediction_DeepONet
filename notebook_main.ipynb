{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33624ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/traitlets/traitlets.py\", line 632, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "KeyError: '_control_lock'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 301, in dispatch_control\n",
      "    async with self._control_lock:\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/traitlets/traitlets.py\", line 687, in __get__\n",
      "    return t.cast(G, self.get(obj, cls))  # the G should encode the Optional\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/traitlets/traitlets.py\", line 649, in get\n",
      "    value = self._validate(obj, default)\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/traitlets/traitlets.py\", line 722, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/traitlets/traitlets.py\", line 2311, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/home/cebille/.venv/lib64/python3.9/site-packages/traitlets/traitlets.py\", line 831, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The '_control_lock' trait of an IPythonKernel instance expected a Lock, not the NoneType None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from config.dataConfig import Config\n",
    "from src.data import SimulationData\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader  \n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from src.models import DeepONet\n",
    "from src.dataset import MultiColDataset\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8163b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class SimulationDataLoader:\n",
    "    def __init__(self):\n",
    "        self.features = None\n",
    "\n",
    "    def save_features(self, path):\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(self.features, f)\n",
    "\n",
    "    def load_features(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            self.features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1483f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SimulationDataLoader()\n",
    "data.load_features('data/features2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7846460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import compute_moment_of_inertia, compute_area_section, compute_local_slenderness_ratio\n",
    "\n",
    "def get_trunk_input_rm(data: SimulationData, column_type: str, i: int, n_time_step=1):\n",
    "    data_col = data.features[column_type]  # 214 time steps\n",
    "\n",
    "    # Static geometric features\n",
    "    d  = data_col[\"d\"]\n",
    "    t_w = data_col[\"t_w\"]\n",
    "    b_f = data_col[\"b_f\"]\n",
    "    t_f = data_col[\"t_f\"]\n",
    "\n",
    "    I = compute_moment_of_inertia(d, t_w, b_f, t_f)\n",
    "    A = compute_area_section(d, t_w, b_f, t_f)\n",
    "    lsr = compute_local_slenderness_ratio(8000, d, t_w, b_f, t_f)\n",
    "\n",
    "    # All displacements as array/list\n",
    "    disp_all = data_col[\"displacements\"]\n",
    "\n",
    "    # Current and next displacement\n",
    "    disp = disp_all[i]\n",
    "    if i < len(disp_all) - 1:\n",
    "        disp_next = disp_all[i + 1]\n",
    "    else:\n",
    "        disp_next = disp  # end of sequence\n",
    "    delta_disp = disp_next - disp\n",
    "    # --------------------------------------------------------------\n",
    "    # Build sequence of n_time_step previous displacements\n",
    "    # --------------------------------------------------------------\n",
    "    disp_seq = []\n",
    "    for k in range(n_time_step):\n",
    "        idx = (i + 1) - (n_time_step - k)   # indexes from (i+1 - n) ... (i)\n",
    "        if idx < 0:\n",
    "            # Not enough history -> use displacement at i\n",
    "            disp_seq.append(disp)\n",
    "        else:\n",
    "            disp_seq.append(disp_all[idx])\n",
    "\n",
    "    #disp_seq.append(horizontal_disp_next)\n",
    "    disp_seq = [disp, disp_next, delta_disp]\n",
    "    #disp_seq.append(delta_disp)\n",
    "    # Convert to numpy array\n",
    "    disp_seq = np.array(disp_seq, dtype=np.float32)  # shape: (n_time_step,)\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # Build final feature vector\n",
    "    # --------------------------------------------------------------\n",
    "    # Static geometry + current disp + next disp + sequence history\n",
    "    features = np.concatenate([\n",
    "        np.array([d, t_w, b_f, t_f], dtype=np.float32),\n",
    "        disp_seq.flatten()\n",
    "    ], axis=0)\n",
    "    return torch.tensor(features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50940bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_type = 'W16X100'\n",
    "i = 0 \n",
    "test = get_trunk_input_rm(data, column_type, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174ce884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764c974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W16X100', 'W16X26', 'W16X31', 'W16X36', 'W16X40', 'W16X45', 'W16X50', 'W16X57', 'W16X67', 'W16X77', 'W16X89', 'W18X106', 'W18X119', 'W18X130', 'W18X35', 'W18X40', 'W18X46', 'W18X50', 'W18X55', 'W18X60', 'W18X65', 'W18X71', 'W18X76', 'W18X86', 'W18X97', 'W21X101', 'W21X111', 'W21X122', 'W21X132', 'W21X44', 'W21X48', 'W21X50', 'W21X55', 'W21X57', 'W21X62', 'W21X68', 'W21X73', 'W21X83', 'W21X93', 'W24X103', 'W24X104', 'W24X117', 'W24X131', 'W24X146', 'W24X55', 'W24X62', 'W24X68', 'W24X76', 'W24X84', 'W24X94', 'W27X102', 'W27X114', 'W27X129', 'W27X146', 'W27X161', 'W27X84', 'W27X94', 'W30X108', 'W30X116', 'W30X124', 'W30X132', 'W30X148', 'W30X173', 'W30X90', 'W30X99', 'W33X118', 'W33X130', 'W33X141', 'W33X152', 'W33X169', 'W33X201', 'W36X135', 'W36X150', 'W36X160', 'W36X170', 'W36X182', 'W36X194', 'W36X210', 'W40X149', 'W40X167', 'W40X183', 'W40X211'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2695b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def moments_scaler(data): \n",
    "    moments = []\n",
    "    for key in data.features:\n",
    "        moments.append(data.features[key][\"resisting_moments\"])\n",
    "\n",
    "    moments = np.concatenate(moments, axis=0)\n",
    "    moments = np.array(moments).reshape(-1,1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    moments_scaled = scaler.fit_transform(moments)\n",
    "    \n",
    "    return scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b73ffbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13937, 1)\n"
     ]
    }
   ],
   "source": [
    "moments = []\n",
    "for key in data.features:\n",
    "    moments.append(data.features[key][\"resisting_moments\"])\n",
    "\n",
    "moments = np.concatenate(moments, axis=0)\n",
    "moments = np.array(moments).reshape(-1,1)\n",
    "print(moments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cece20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.15719579e-18]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "moments_scaled = scaler.fit_transform(moments)\n",
    "print(moments_scaled.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc6cad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_moments = []\n",
    "for key in data.features:\n",
    "    max_moments.append(np.max(data.features[key][\"resisting_moments\"]))\n",
    "\n",
    "#max_moments = np.concatenate(max_moments, axis=0)\n",
    "#max_moments = np.array(max_moments).reshape(-1,1)\n",
    "#print(max_moments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a47a40d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(np.array(max_moments), bins=20)\n",
    "plt.xlabel('Max reaction moment, N*mm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1834d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reserve_capacities', 'resisting_moments', 'horizontal_displacements', 'loading_protocols', 'coordinate_features', 'deviation_features', 'curvature_features', 'edge_index', 'edge_features', 'd', 't_w', 'b_f', 't_f', 'edge_norms', 'In-distribution test', 'Out-of-distribution test'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.features[\"W16X100\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "390b698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded and set to evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cebille/ReserveCapacityPrediction_DeepONet/src/dataset.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_trunk_inputs.append(torch.tensor(trunk_input, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from src.utils import compute_local_slenderness_ratio\n",
    "\n",
    "from config.dataConfig import Config\n",
    "from src.data import SimulationData\n",
    "from src.dataset import MultiColDataset\n",
    "from src.dataset import compute_normalization_stats, compute_graph_norm_stats\n",
    "from src.utils import compute_mean_target, compute_std_target\n",
    "from src.models import DeepONet\n",
    "from collections import defaultdict\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import imageio\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "def get_coords_timestep_i(data:SimulationData , column_type:str, i:int):\n",
    "    data_col = data.features[column_type] # 214 timesteps\n",
    "    node_coords = torch.tensor(data_col[\"coordinate_features\"][i].reshape(-1, 3), dtype=torch.float32) # (70,3) timestep i\n",
    "\n",
    "    return node_coords\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "def make_importance_gif_dynamic_graph(data, importance_list, col_type,\n",
    "                                      gif_path=\"ReserveCapacityPrediction_DeepONet/figures/gifs/node_importance.gif\",\n",
    "                                      elev=20, azim=45):\n",
    "\n",
    "    os.makedirs(os.path.dirname(gif_path), exist_ok=True)\n",
    "\n",
    "    # Normalize global importance values for stable color scale\n",
    "    all_imps = torch.stack(importance_list).cpu().numpy()\n",
    "    importances = all_imps[-100:]\n",
    "    global_min = importances.min()\n",
    "    global_max = importances.max()\n",
    "\n",
    "    # Get node coordinates for all timesteps\n",
    "    all_pos = [get_coords_timestep_i(data, col_type, t) for t in range(len(importance_list))]\n",
    "    all_pos = np.array(all_pos)\n",
    "    \n",
    "    posistions = all_pos[-100:]\n",
    "    # Compute global axis limits\n",
    "    x_min, y_min, z_min = posistions.min(axis=(0,1))\n",
    "    x_max, y_max, z_max = posistions.max(axis=(0,1))\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for t, imp in enumerate(importances):\n",
    "        pos = posistions[t]\n",
    "        #imp = imp.detach().cpu().numpy()\n",
    "\n",
    "        fig = plt.figure(figsize=(7, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Scatter plot with **fixed vmin/vmax** for colorbar\n",
    "        sc = ax.scatter(\n",
    "            pos[:, 0], pos[:, 1], pos[:, 2],\n",
    "            c=imp,\n",
    "            cmap=\"viridis\",\n",
    "            s=40,\n",
    "            vmin=global_min,\n",
    "            vmax=global_max\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"Node Importance – t = {t}\")\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        ax.set_zlabel(\"Z\")\n",
    "\n",
    "        # Fixed camera view\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "        # Set fixed axis limits\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_zlim(z_min, z_max)\n",
    "\n",
    "        # Colorbar with fixed scale\n",
    "        cbar = fig.colorbar(sc, ax=ax, shrink=0.6)\n",
    "        cbar.set_label('Node Importance')\n",
    "\n",
    "        # Optionally 5 evenly spaced ticks\n",
    "        tick_labels = np.linspace(global_min, global_max, 5)\n",
    "        cbar.set_ticks(tick_labels)\n",
    "        cbar.set_ticklabels([f\"{v:.4f}\" for v in tick_labels])\n",
    "\n",
    "        # Save frame\n",
    "        frame_path = f\"_tmp_frame_{t}.png\"\n",
    "        plt.savefig(frame_path, dpi=120)\n",
    "        plt.close()\n",
    "\n",
    "        frames.append(imageio.imread(frame_path))\n",
    "\n",
    "    # Build GIF\n",
    "    imageio.mimsave(gif_path, frames, fps=5)\n",
    "\n",
    "    # Cleanup\n",
    "    for t in range(len(frames)):\n",
    "        os.remove(f\"_tmp_frame_{t}.png\")\n",
    "\n",
    "    print(f\"GIF saved to: {gif_path}\")\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Subset\n",
    "import shap  # Make sure shap is installed\n",
    "\n",
    "# === 1. Load trained model ===\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = DeepONet(branch_in=7, trunk_in=4, hidden_dim=264, hidden_dim_trunk=264,\n",
    "                 latent_dim=128, out_dim=2, dropout=0.2).to(device)\n",
    "state_dict = torch.load(\"../best_deeponet_model.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded and set to evaluation mode.\")\n",
    "\n",
    "# === 2. Prepare DataLoader ===\n",
    "config = Config()\n",
    "data = SimulationData(config)\n",
    "data.load_features('data/features.pkl')\n",
    "\n",
    "trunk_mean, trunk_std = compute_normalization_stats(data)\n",
    "graph_mean, graph_std = compute_graph_norm_stats(data)\n",
    "dataset = MultiColDataset(data, trunk_mean, trunk_std, graph_mean, graph_std)\n",
    "\n",
    "trunk_mean, trunk_std = trunk_mean.to(device), trunk_std.to(device)\n",
    "graph_mean, graph_std = graph_mean.to(device), graph_std.to(device)\n",
    "\n",
    "# Separate by flags\n",
    "test_set = \"in_flag\"\n",
    "train_val_samples, test_samples = [], []\n",
    "for i, sample in enumerate(dataset.samples):\n",
    "    if sample[test_set]:\n",
    "        test_samples.append(i)\n",
    "    else:\n",
    "        train_val_samples.append(i)\n",
    "\n",
    "train_size = int(0.001 * len(train_val_samples))\n",
    "train_samples = range(train_size)  # list/range of indices\n",
    "train_dataset = Subset(dataset, train_samples)\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5b29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONetSHAPWrapper(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SHAP-compatible wrapper.\n",
    "    Inputs:\n",
    "        x_flat: flattened node features (1 x (N*F))\n",
    "    Behavior:\n",
    "        - reshapes node features back into graph.x\n",
    "        - keeps graph structure and trunk input fixed\n",
    "        - runs full DeepONet → scalar\n",
    "    \"\"\"\n",
    "    def __init__(self, model, edge_index, edge_attr, trunk_input, output_component):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_attr = edge_attr\n",
    "        self.trunk_input = trunk_input\n",
    "        self.output_component = output_component\n",
    "        self.num_nodes = edge_index.max().item() + 1\n",
    "\n",
    "    def forward(self, x_flat):\n",
    "        B = x_flat.size(0)\n",
    "        num_features = x_flat.size(1) // self.num_nodes\n",
    "\n",
    "        # reshape into graph node feature matrix\n",
    "        x = x_flat.view(B, self.num_nodes, num_features)\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(B):\n",
    "            graph = Data(\n",
    "                x=x[i],\n",
    "                edge_index=self.edge_index,\n",
    "                edge_attr=self.edge_attr\n",
    "            )\n",
    "            # Full DeepONet: branch(graph) + trunk(trunk_input)\n",
    "            y = self.model(graph, self.trunk_input)\n",
    "            y = y.view(-1)    \n",
    "            y_scalar = y[self.output_component]\n",
    "            outputs.append(y_scalar)\n",
    "\n",
    "        return torch.stack(outputs, dim=0).squeeze(-1)  # shape (B,)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. Build SHAP background dataset\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "background_x = []\n",
    "max_background = 20\n",
    "\n",
    "for graph, trunk_input, target, _, _, _ in loader:\n",
    "    graph = graph.to(device)\n",
    "    if len(background_x) < max_background:\n",
    "        background_x.append(graph.x.view(1, -1))\n",
    "\n",
    "background = torch.cat(background_x, dim=0)  # shape: [B, N*F]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cba06b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n",
      "torch.Size([1, 490])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m x_flat \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_flat\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 36\u001b[0m shap_vals \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_flat\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]       \u001b[38;5;66;03m# numpy\u001b[39;00m\n\u001b[1;32m     37\u001b[0m shap_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(shap_vals)\u001b[38;5;241m.\u001b[39mview(graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Node-level importance\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/shap/explainers/_gradient.py:160\u001b[0m, in \u001b[0;36mGradientExplainer.shap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshap_values\u001b[39m(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, nsamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, rseed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_variances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    110\u001b[0m ):\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the values for the model applied to X.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_variances\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/shap/explainers/_gradient.py:613\u001b[0m, in \u001b[0;36m_PyTorchGradient.shap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, nsamples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m    610\u001b[0m     batch \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    611\u001b[0m         samples_input[c][b : \u001b[38;5;28mmin\u001b[39m(b \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, nsamples)]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))\n\u001b[1;32m    612\u001b[0m     ]\n\u001b[0;32m--> 613\u001b[0m     grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    614\u001b[0m grad \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mconcatenate([g[z] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads], \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata))]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/shap/explainers/_gradient.py:482\u001b[0m, in \u001b[0;36m_PyTorchGradient.gradient\u001b[0;34m(self, idx, inputs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    481\u001b[0m X \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mrequires_grad_() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m--> 482\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m selected \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m outputs[:, idx]]\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36mDeepONetSHAPWrapper.forward\u001b[0;34m(self, x_flat)\u001b[0m\n\u001b[1;32m     29\u001b[0m graph \u001b[38;5;241m=\u001b[39m Data(\n\u001b[1;32m     30\u001b[0m     x\u001b[38;5;241m=\u001b[39mx[i],\n\u001b[1;32m     31\u001b[0m     edge_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_index,\n\u001b[1;32m     32\u001b[0m     edge_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Full DeepONet: branch(graph) + trunk(trunk_input)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrunk_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)    \n\u001b[1;32m     37\u001b[0m y_scalar \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_component]\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ReserveCapacityPrediction_DeepONet/src/models.py:109\u001b[0m, in \u001b[0;36mDeepONet.forward\u001b[0;34m(self, u_samples, x_loc)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, u_samples, x_loc):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    u_samples : (batch, branch_in_dim)  - discretized function\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    x_loc     : (batch, trunk_in_dim)   - evaluation coordinates\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    returns   : (batch, output_dim)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_samples\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# (batch, out_dim * latent_dim)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk(x_loc)    \u001b[38;5;66;03m# (batch, out_dim * latent_dim)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Reshape to (batch, out_dim, latent_dim)\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m#b = b.view(-1, self.out_dim, self.latent_dim)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m#t = t.view(-1, self.out_dim, self.latent_dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Dot product (key line)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/ReserveCapacityPrediction_DeepONet/src/models.py:48\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m---> 48\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(x)\n\u001b[1;32m     50\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_wkd3va_v.py:245\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    236\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    237\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[1;32m    238\u001b[0m                 edge_weight\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39medge_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    579\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    583\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    584\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# 5. Compute SHAP per-sample\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "importance_by_col = defaultdict(list)\n",
    "shap_values_by_col = defaultdict(list)\n",
    "\n",
    "col_filter = \"W16X100\"\n",
    "\n",
    "# Use the first graph to instantiate the wrapper\n",
    "ref_graph, ref_trunk_input, _, _, _, _ = next(iter(loader))\n",
    "ref_graph, ref_trunk_input = ref_graph.to(device), ref_trunk_input.to(device)\n",
    "\n",
    "shap_model = DeepONetSHAPWrapper(\n",
    "    model=model,\n",
    "    edge_index=ref_graph.edge_index,\n",
    "    edge_attr=ref_graph.edge_attr,\n",
    "    trunk_input=ref_trunk_input,\n",
    "    output_component=0\n",
    ").to(device)\n",
    "\n",
    "explainer = shap.GradientExplainer(shap_model, background.to(device))\n",
    "print(\"done1\")\n",
    "\n",
    "for graph, trunk_input, target, in_flag, out_flag, col in loader:\n",
    "    print(\"done2\")\n",
    "    graph = graph.to(device)\n",
    "    trunk_input = trunk_input.to(device)\n",
    "\n",
    "    # Update wrapper trunk input for current sample\n",
    "    shap_model.trunk_input = trunk_input\n",
    "\n",
    "    x_flat = graph.x.view(1, -1).to(device)\n",
    "    print(x_flat.shape)\n",
    "\n",
    "    shap_vals = explainer.shap_values(x_flat)[0]       # numpy\n",
    "    shap_vals = torch.tensor(shap_vals).view(graph.x.shape)\n",
    "\n",
    "    # Node-level importance\n",
    "    node_imp = shap_vals.abs().sum(dim=1)\n",
    "\n",
    "    shap_values_by_col[col[0]].append(shap_vals.cpu())\n",
    "    importance_by_col[col[0]].append(node_imp.cpu())\n",
    "\n",
    "print(\"importance calculation done.\")\n",
    "print(importance_by_col[col[0]][0])\n",
    "print(shap_values_by_col[col[0]][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
